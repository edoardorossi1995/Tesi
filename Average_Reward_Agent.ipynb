{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3vWTd_Ih2p9d"
      ],
      "authorship_tag": "ABX9TyMxp1VNtGtK3/fuJgPb7X7s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edoardorossi1995/Tesi/blob/main/Average_Reward_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pseudocodice \n",
        "###Algoritmo di tipo Q-learning, off policy, a task non episodico, che approssima la funzione valore con una rete neurale, con un framework di tipo average reward."
      ],
      "metadata": {
        "id": "3vWTd_Ih2p9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Drive Setting\n"
      ],
      "metadata": {
        "id": "q46girwt63TH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jajCZgNk6wXT",
        "outputId": "ee04abaf-0277-41e0-eae3-2cbb490e8958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Tesi\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB == True:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  %cd /content/gdrive/MyDrive/Tesi\n",
        "  #!ls\n",
        "\n",
        "import warnings\n",
        "import pickle\n",
        "import sys\n",
        "sys.path.insert(0, '/content/gdrive/MyDrive/Tesi/functions')\n",
        "sys.path.insert(0, '/content/gdrive/MyDrive/Tesi')\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Lambda\n",
        "from keras.activations import exponential, relu\n",
        "from keras import backend as K\n",
        "\n",
        "from pkl import store_data, load_data\n",
        "from functions.compressor import compress\n",
        "\n",
        "import random\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Anagrafica e CTA"
      ],
      "metadata": {
        "id": "nQw2LmXT7FOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import pandas as pd\n",
        "#import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "CTA30_def = ['/content/gdrive/MyDrive/Tesi/CTA30/DF_clean/clean_CTA_30_def.csv']\n",
        "df_def = pd.read_csv(CTA30_def[0])\n",
        "\n",
        "CTA30_18 = ['/content/gdrive/MyDrive/Tesi/CTA30/DF_clean/clean_CTA_30_2018.csv']\n",
        "df = pd.read_csv(CTA30_18[0])\n",
        "df['VLV_RAF_FDBK_00'] = df['VLV_RAF_FDBK_00'] / 100\n",
        "df['VLV_SUR_FDBK_00'] = df['VLV_SUR_FDBK_00'] / 100\n",
        "scaler = MinMaxScaler()\n",
        "act_f_m = df.loc[:,'F_M_FDBK_00']\n",
        "a_f_m_reshaped = np.array(act_f_m).reshape(-1, 1)\n",
        "a_f_m_scaled = scaler.fit_transform(a_f_m_reshaped)\n",
        "\n",
        "pca_df = compress(df)"
      ],
      "metadata": {
        "id": "v7Tx5Dbc6y7G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Anagrafica shape:\",df_def.shape,\"\\nDataframe shape:\", df.shape,\"\\nPca Dataframe shape:\", pca_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QMdpC4_8QV-",
        "outputId": "ca741779-221b-42a0-ddda-e6f482704b21"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anagrafica shape: (76, 2) \n",
            "Dataframe shape: (141811, 76) \n",
            "Pca Dataframe shape: (141811, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_def"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sQRpOWyFHXi6",
        "outputId": "f2170161-e628-495c-cd0c-1e805e87c658"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           pointColName                            pointName\n",
              "0   AUTOMAN_SERR_CMD_00  Automatico Manuale Serrande Comando\n",
              "1    AUTOMAN_VLV_CMD_00   Automatico Manuale Valvole Comando\n",
              "2      AUTOMAN_M_CMD_00   Automatico Manuale Mandata Comando\n",
              "3      AUTOMAN_R_CMD_00   Automatico Manuale Ripresa Comando\n",
              "4         LOCREM_CMD_00      Selettore Locale Remoto Comando\n",
              "..                  ...                                  ...\n",
              "71            VOLT_R_00                     Tensione Ripresa\n",
              "72            T_M_SP_00    Temperatura Aria Mandata Setpoint\n",
              "73            T_R_SP_00    Temperatura Aria Ritorno Setpoint\n",
              "74             T_AMB_04      Temperatura Aria Ambiente Media\n",
              "75        AUTOMAN_ST_00             Automatico Manuale Stato\n",
              "\n",
              "[76 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f0c7a73-b97b-480c-a6f1-990dd46c781f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pointColName</th>\n",
              "      <th>pointName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AUTOMAN_SERR_CMD_00</td>\n",
              "      <td>Automatico Manuale Serrande Comando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AUTOMAN_VLV_CMD_00</td>\n",
              "      <td>Automatico Manuale Valvole Comando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AUTOMAN_M_CMD_00</td>\n",
              "      <td>Automatico Manuale Mandata Comando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AUTOMAN_R_CMD_00</td>\n",
              "      <td>Automatico Manuale Ripresa Comando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LOCREM_CMD_00</td>\n",
              "      <td>Selettore Locale Remoto Comando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>VOLT_R_00</td>\n",
              "      <td>Tensione Ripresa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>T_M_SP_00</td>\n",
              "      <td>Temperatura Aria Mandata Setpoint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>T_R_SP_00</td>\n",
              "      <td>Temperatura Aria Ritorno Setpoint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>T_AMB_04</td>\n",
              "      <td>Temperatura Aria Ambiente Media</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>AUTOMAN_ST_00</td>\n",
              "      <td>Automatico Manuale Stato</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f0c7a73-b97b-480c-a6f1-990dd46c781f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f0c7a73-b97b-480c-a6f1-990dd46c781f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f0c7a73-b97b-480c-a6f1-990dd46c781f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rete Neurale\n",
        "\n",
        "Log-sum-exp neural networks and posynomial\n",
        "models for convex and log-log-convex data \n",
        "\n",
        "(Calafiore, Gaubert, Possieri)"
      ],
      "metadata": {
        "id": "SmYeYm2EJYFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = load_data('*.pkl')\n",
        "action_vector_dimension = 2\n",
        "\n",
        "# Funzione di attivazione logatirmica (ultimo strato)\n",
        "def log_act(x):\n",
        "  return K.log(x)\n",
        "\n",
        "# Architettura rete neurale\n",
        "input_dim = n['n_components']+action_vector_dimension\n",
        "inner_dim_1 = 32\n",
        "output_dim = 1\n",
        "\n",
        "print(\"input dim: \", input_dim)\n",
        "print(\"inner layer dim: \", inner_dim_1)\n",
        "print(\"output dim: \", output_dim)\n",
        "\n",
        "# Costruzione strati\n",
        "rete_neurale = Sequential()\n",
        "rete_neurale.add(Dense(units = inner_dim_1, activation = exponential, input_dim = input_dim))\n",
        "rete_neurale.add(Dense(units = output_dim, activation=log_act)) \n",
        "\n",
        "rete_neurale.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "nSB60YSmJZ_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18c7f8d-2593-4850-a838-52d411a74382"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input dim:  9\n",
            "inner layer dim:  32\n",
            "output dim:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "min_f = np.min(a_f_m_scaled)\n",
        "max_f = np.max(a_f_m_scaled)\n",
        "\n",
        "data_f = np.random.uniform(min_f, max_f, 100)\n",
        "list_a = [0.0, 0.5, 1.0]\n",
        "data_a = np.array(list_a)\n",
        "pca_s_prime = pca_df.loc[np.random.randint(0,40000),:]\n",
        "nn_input_prime = np.concatenate((pca_s_prime.values.reshape(7,1), data_f[0].reshape(1,1), data_a[2].reshape(1,1)),axis = 0)\n",
        "nn_input_prime = np.reshape(nn_input_prime, (1,input_dim))\n",
        "funct = rete_neurale.predict(nn_input_prime, verbose = 0)[0][0]\n"
      ],
      "metadata": {
        "id": "wr1ZrHZfMbx8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(x):\n",
        "    nn_input_prime = np.concatenate((pca_s_prime.values.reshape(7,1), x[0].reshape(1,1), x[1].reshape(1,1)), axis=0)\n",
        "    nn_input_prime = np.reshape(nn_input_prime, (1,input_dim))\n",
        "    funct = rete_neurale.predict(nn_input_prime, verbose=0)[0][0]\n",
        "    return -funct\n",
        "\n",
        "\n",
        "\n",
        "x0 = [data_f[np.random.randint(len(data_f))],data_a[np.random.randint(len(data_a))]]\n",
        "bounds = [(min_f, max_f), (0,1)]\n",
        "q_prime = minimize(objective, x0, method = 'Nelder-Mead', bounds = bounds)\n",
        "\n",
        "print(\"funct = \", -q_prime.fun)\n",
        "print(\"x0 = \", x0)\n",
        "print(\"x = \", q_prime.x)\n",
        "#print(\"q_prime = \", rete_neurale.predict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfDwGD1i7ptC",
        "outputId": "835bbc5c-7894-40fa-a7fd-42cd3062f381"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "funct =  1.066624641418457\n",
            "x0 =  [0.9924442680191305, 0.0]\n",
            "x =  [0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q-Learning Agent"
      ],
      "metadata": {
        "id": "_KF3EgbAI_y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensione problema e inizializzazione stato iniziale\n",
        "[S, feat] = df.shape\n",
        "current_state = 1500#np.random.randint(0,S-1)\n",
        "\n",
        "# Inizializza la media delle ricompense future attese per ogni stato-azione a zero\n",
        "q = 0\n",
        "\n",
        "min_f = np.min(a_f_m_scaled)\n",
        "max_f = np.max(a_f_m_scaled)\n",
        "\n",
        "# Stato corrente\n",
        "s = current_state\n",
        "\n",
        "# Parametri di apprendimento (learning rate, discount factor, average rate)\n",
        "alpha = 0.5\n",
        "gamma = 1\n",
        "beta = 0.5\n",
        "\n",
        "# Media mobile esponenziale (avr = avr + beta * (r - avr)) \n",
        "# [scelta perchÃ© computazionalmente piÃ¹ leggera di una media aritmetica]\n",
        "average_reward = 0\n",
        "\n",
        "# Setting Episodi\n",
        "total_episodes = 3\n",
        "current_episode = 0\n",
        "\n",
        "# Ripeti finchÃ© non raggiungi la fine del processo\n",
        "for current_episode in range(total_episodes):\n",
        "    \n",
        "    # Stato successivo e ottieni l'azione A e la ricompensa R\n",
        "    s_prime = s+1\n",
        "    if s_prime > S-1:\n",
        "      print(\"s =\",s)\n",
        "      break\n",
        "\n",
        "    #a1 = df.loc[s,'F_M_FDBK_00']-df.loc[s_prime,'F_M_FDBK_00']\n",
        "    a1 = df.loc[s,'F_M_FDBK_00']\n",
        "    #a2 = df.loc[s,'VLV_RAF_FDBK_00']-df.loc[s_prime,'VLV_RAF_FDBK_00']\n",
        "    a2 = df.loc[s,'VLV_RAF_FDBK_00']\n",
        "    a = (a1,a2)\n",
        "    r = -df.loc[s,'PW_ATT_M_00']\n",
        "\n",
        "    average_reward = average_reward + beta * (r - average_reward)\n",
        "\n",
        "    # Comprimo s per generare un valore di input per la predizione di q(s,a)\n",
        "    pca_s = pca_df.loc[s,:]\n",
        "    nn_input = np.concatenate((pca_s.values, np.array([a[0],a[1]])))\n",
        "    nn_input = np.reshape(nn_input, (1,input_dim))\n",
        "\n",
        "    q = rete_neurale.predict(nn_input_prime, verbose = 0)[0]\n",
        "\n",
        "    # Comprimo s_prime per generare un valore di input_prime per la predizione di q(s',a')\n",
        "    data_f = np.random.uniform(min_f, max_f, 100)\n",
        "    list_a = [0.0, 0.5, 1.0]\n",
        "    data_a = np.array(list_a)\n",
        "    pca_s_prime = pca_df.loc[s_prime,:]\n",
        "\n",
        "    q_prime_max = 0\n",
        "\n",
        "    # Iterazione sulle azioni per verificare\n",
        "    for i in range(data_f.size):\n",
        "      for j in range(data_a.size):\n",
        "        nn_input_prime = np.concatenate((pca_s_prime.values.reshape(7,1), data_f[i].reshape(1,1), data_a[j].reshape(1,1)),axis = 0)\n",
        "        nn_input_prime = np.reshape(nn_input_prime, (1,input_dim))\n",
        "        q_prime = rete_neurale.predict(nn_input_prime, verbose = 0)[0]\n",
        "        if q_prime > q_prime_max:\n",
        "          q_prime_max = q_prime\n",
        "\n",
        "    # Calcola la media delle ricompense future attese per lo stato-azione corrente\n",
        "    # q = q + a*(avr + gamma*max(q') - q)\n",
        "    q = average_reward + gamma * (q_prime)\n",
        "\n",
        "    # Calcola il valore target per il training della rete neurale\n",
        "    target = q\n",
        "    target = np.array([target])\n",
        "\n",
        "    # Aggiorna la rete neurale\n",
        "    rete_neurale.fit(nn_input, target, epochs=1, verbose=0)\n",
        "\n",
        "    # Aggiorna lo stato corrente\n",
        "    s = s_prime\n",
        "\n",
        "    # Plot statistiche ogni 100 episodi\n",
        "    if current_episode%1 == 0:\n",
        "      print(\"Episodio \",current_episode,\"/\",total_episodes)\n",
        "      print(\"target: \", target, \"\\nreward: \",r,\"\\naverage_reward: \",np.mean(average_reward))\n",
        "      print(\"\\n\")\n",
        "\n",
        "# Restituisci la rete neurale ottenuta\n",
        "#return rete_neurale"
      ],
      "metadata": {
        "id": "JKjOlbwU42vQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}