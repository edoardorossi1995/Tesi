{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3vWTd_Ih2p9d",
        "nQw2LmXT7FOT"
      ],
      "authorship_tag": "ABX9TyMxwxivmOqt2f37AWNndXCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edoardorossi1995/Tesi/blob/main/Learning_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pseudocodice \n",
        "###Algoritmo di tipo Q-learning, off policy, a task non episodico, che approssima la funzione valore con una rete neurale, con un framework di tipo average reward."
      ],
      "metadata": {
        "id": "3vWTd_Ih2p9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inizializza la rete neurale per approssimare la funzione Q\n",
        "\n",
        "Inizializza la media delle ricompense future attese per ogni stato-azione a zero\n",
        "\n",
        "Ripeti finché non raggiungi la fine del processo:\n",
        "\n",
        "- S = stato corrente\n",
        "\n",
        "- Seleziona un'azione A seguendo la politica di esplorazione (ad esempio, la politica ε-greedy)\n",
        "- Esegui l'azione A e ottieni il prossimo stato S' e la ricompensa R\n",
        "- Calcola la media delle ricompense future attese per lo stato-azione corrente utilizzando la formula:\n",
        "- - media_ricompense[S, A] = (1 - α) * media_ricompense[S, A] + α * (R + γ * max(Q(S', a), rete_neurale))\n",
        "- Calcola il valore target utilizzando la formula:\n",
        "- - target = media_ricompense[S, A]\n",
        "- Aggiorna la rete neurale utilizzando il valore target come obiettivo e il vettore di stato-azione come input S = S'\n",
        "\n",
        "Restituisci la **rete neurale** ottenuta\n"
      ],
      "metadata": {
        "id": "-ZfLAv0z2A8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Drive Setting\n"
      ],
      "metadata": {
        "id": "q46girwt63TH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jajCZgNk6wXT",
        "outputId": "16ba966f-bf7d-4517-d78f-72a3500c1636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/Tesi\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB == True:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  %cd /content/gdrive/MyDrive/Tesi\n",
        "  #!ls\n",
        "\n",
        "import warnings\n",
        "import pickle\n",
        "import sys\n",
        "sys.path.insert(0, '/content/gdrive/MyDrive/Tesi/functions')\n",
        "sys.path.insert(0, '/content/gdrive/MyDrive/Tesi')\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/gdrive/MyDrive/Tesi/functions'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkJiNUL2tSiA",
        "outputId": "61734ec8-36bb-4877-a367-0220b05b0850"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compressor.py  pkl.py  __pycache__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Lambda\n",
        "from keras.activations import exponential, relu\n",
        "from keras import backend as K\n",
        "\n",
        "from pkl import store_data, load_data\n",
        "from functions.compressor import compress\n",
        "\n",
        "import random\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "UsTVN33etAWJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Anagrafica e CTA"
      ],
      "metadata": {
        "id": "nQw2LmXT7FOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import pandas as pd\n",
        "#import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "CTA30_def = ['/content/gdrive/MyDrive/Tesi/CTA30/DF_clean/clean_CTA_30_def.csv']\n",
        "df_def = pd.read_csv(CTA30_def[0])\n",
        "\n",
        "CTA30_18 = ['/content/gdrive/MyDrive/Tesi/CTA30/DF_clean/clean_CTA_30_2018.csv']\n",
        "df = pd.read_csv(CTA30_18[0])\n",
        "\n",
        "pca_df = compress(df)"
      ],
      "metadata": {
        "id": "v7Tx5Dbc6y7G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Anagrafica shape:\",df_def.shape,\"\\nDataframe shape:\", df.shape,\"\\nPca Dataframe shape:\", pca_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QMdpC4_8QV-",
        "outputId": "3b7a310e-4332-48a2-dd12-7a2ac98e8b04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anagrafica shape: (76, 2) \n",
            "Dataframe shape: (141811, 76) \n",
            "Pca Dataframe shape: (141811, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_def"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1742
        },
        "id": "sQRpOWyFHXi6",
        "outputId": "d8c9954c-1333-4235-d362-ef2ca67db584"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           pointColName                            pointName\n",
              "0   AUTOMAN_SERR_CMD_00  Automatico Manuale Serrande Comando\n",
              "1    AUTOMAN_VLV_CMD_00   Automatico Manuale Valvole Comando\n",
              "2      AUTOMAN_M_CMD_00   Automatico Manuale Mandata Comando\n",
              "3      AUTOMAN_R_CMD_00   Automatico Manuale Ripresa Comando\n",
              "4         LOCREM_CMD_00      Selettore Locale Remoto Comando\n",
              "..                  ...                                  ...\n",
              "71            VOLT_R_00                     Tensione Ripresa\n",
              "72            T_M_SP_00    Temperatura Aria Mandata Setpoint\n",
              "73            T_R_SP_00    Temperatura Aria Ritorno Setpoint\n",
              "74             T_AMB_04      Temperatura Aria Ambiente Media\n",
              "75        AUTOMAN_ST_00             Automatico Manuale Stato\n",
              "\n",
              "[76 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2da3ebad-30a8-47d9-9ee0-c063f75b6db4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pointColName</th>\n",
              "      <th>pointName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AUTOMAN_SERR_CMD_00</td>\n",
              "      <td>Automatico Manuale Serrande Comando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AUTOMAN_VLV_CMD_00</td>\n",
              "      <td>Automatico Manuale Valvole Comando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AUTOMAN_M_CMD_00</td>\n",
              "      <td>Automatico Manuale Mandata Comando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AUTOMAN_R_CMD_00</td>\n",
              "      <td>Automatico Manuale Ripresa Comando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LOCREM_CMD_00</td>\n",
              "      <td>Selettore Locale Remoto Comando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>VOLT_R_00</td>\n",
              "      <td>Tensione Ripresa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>T_M_SP_00</td>\n",
              "      <td>Temperatura Aria Mandata Setpoint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>T_R_SP_00</td>\n",
              "      <td>Temperatura Aria Ritorno Setpoint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>T_AMB_04</td>\n",
              "      <td>Temperatura Aria Ambiente Media</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>AUTOMAN_ST_00</td>\n",
              "      <td>Automatico Manuale Stato</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2da3ebad-30a8-47d9-9ee0-c063f75b6db4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2da3ebad-30a8-47d9-9ee0-c063f75b6db4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2da3ebad-30a8-47d9-9ee0-c063f75b6db4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rete Neurale\n",
        "\n",
        "Log-sum-exp neural networks and posynomial\n",
        "models for convex and log-log-convex data \n",
        "\n",
        "(Calafiore, Gaubert, Possieri)"
      ],
      "metadata": {
        "id": "SmYeYm2EJYFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = load_data('*.pkl')\n",
        "\n",
        "# Funzione di attivazione logatirmica (ultimo strato)\n",
        "def log_act(x):\n",
        "  return K.log(x)\n",
        "\n",
        "# Architettura rete neurale\n",
        "input_dim = n['n_components']+1\n",
        "inner_dim_1 = 32\n",
        "output_dim = 1\n",
        "\n",
        "print(\"input dim: \", input_dim)\n",
        "print(\"inner layer dim: \", inner_dim_1)\n",
        "print(\"output dim: \", output_dim)\n",
        "\n",
        "# Costruzione strati\n",
        "rete_neurale = Sequential()\n",
        "rete_neurale.add(Dense(units = inner_dim_1, activation = exponential, input_dim = input_dim))\n",
        "rete_neurale.add(Dense(units = output_dim, activation=log_act)) \n",
        "\n",
        "rete_neurale.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "nSB60YSmJZ_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd35acc-ba1e-49f6-9c51-25a0325de13b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input dim:  8\n",
            "inner layer dim:  32\n",
            "output dim:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q-Learning Agent"
      ],
      "metadata": {
        "id": "_KF3EgbAI_y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensione problema e inizializzazione stato iniziale\n",
        "[S, feat] = df.shape\n",
        "current_state = np.random.randint(0,S-1)\n",
        "\n",
        "# Inizializza la media delle ricompense future attese per ogni stato-azione a zero\n",
        "q = defaultdict(float)\n",
        "rewards = []\n",
        "\n",
        "# Parametri di apprendimento\n",
        "# alpha = 1\n",
        "# gamma = 1\n",
        "\n",
        "total_episodes = 10\n",
        "current_episode = 0\n",
        "\n",
        "# Stato corrente\n",
        "s = current_state\n",
        "\n",
        "# Ripeti finché non raggiungi la fine del processo\n",
        "for current_episode in range(total_episodes):\n",
        "    \n",
        "    print(\"Episodio \",current_episode,\"/\",total_episodes)\n",
        "\n",
        "    # Stato successivo e ottieni l'azione A e la ricompensa R\n",
        "    s_prime = s+1\n",
        "\n",
        "    a = df.loc[s,'F_M_FDBK_00']-df.loc[s_prime,'F_M_FDBK_00']\n",
        "    r = -df.loc[s,'PW_ATT_M_00']\n",
        "    rewards.append(r)\n",
        "\n",
        "    # Calcola la media delle ricompense future attese per lo stato-azione corrente\n",
        "    # media_ricompense[(s, a)] = (1 - alpha) * media_ricompense[(s, a)] + alpha * (r + gamma * np.max(rete_neurale.predict(s_prime)))\n",
        "    q[(s,a)] = r - np.mean(rewards)\n",
        "\n",
        "    # Calcola il valore target\n",
        "    target = q[(s,a)]\n",
        "    print(\"target: \", target, \"\\nr: \",r,\"\\nreward medio: \",np.mean(rewards))\n",
        "\n",
        "    # Comprimo lo stato e genero l'input della rete neurale\n",
        "    pca_s = pca_df.loc[s,:]\n",
        "\n",
        "    nn_input = np.concatenate((pca_s.values, np.array([a])))\n",
        "    nn_input = np.reshape(nn_input, (1,input_dim))\n",
        "    target = np.array([target])\n",
        "\n",
        "    # Aggiorna la rete neurale\n",
        "    rete_neurale.fit(nn_input, target, epochs=1, verbose=0)\n",
        "\n",
        "    # Aggiorna lo stato corrente\n",
        "    s = s_prime\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Restituisci la rete neurale ottenuta\n",
        "#return rete_neurale"
      ],
      "metadata": {
        "id": "CXoVycO70oDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3114ab66-4f35-41a8-c979-c8e0f3aaf5cb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episodio  0 / 10\n",
            "target:  -0.0 \n",
            "r:  -0.0 \n",
            "reward medio:  0.0\n",
            "\n",
            "\n",
            "Episodio  1 / 10\n",
            "target:  -0.0 \n",
            "r:  -0.0 \n",
            "reward medio:  0.0\n",
            "\n",
            "\n",
            "Episodio  2 / 10\n",
            "target:  -0.0 \n",
            "r:  -0.0 \n",
            "reward medio:  0.0\n",
            "\n",
            "\n",
            "Episodio  3 / 10\n",
            "target:  -0.0 \n",
            "r:  -0.0 \n",
            "reward medio:  0.0\n",
            "\n",
            "\n",
            "Episodio  4 / 10\n",
            "target:  -0.0 \n",
            "r:  -0.0 \n",
            "reward medio:  0.0\n",
            "\n",
            "\n",
            "Episodio  5 / 10\n",
            "target:  -0.0 \n",
            "r:  -0.0 \n",
            "reward medio:  0.0\n",
            "\n",
            "\n",
            "Episodio  6 / 10\n",
            "target:  -0.0 \n",
            "r:  -0.0 \n",
            "reward medio:  0.0\n",
            "\n",
            "\n",
            "Episodio  7 / 10\n",
            "target:  -0.0 \n",
            "r:  -0.0 \n",
            "reward medio:  0.0\n",
            "\n",
            "\n",
            "Episodio  8 / 10\n",
            "target:  -0.0 \n",
            "r:  -0.0 \n",
            "reward medio:  0.0\n",
            "\n",
            "\n",
            "Episodio  9 / 10\n",
            "target:  -0.0 \n",
            "r:  -0.0 \n",
            "reward medio:  0.0\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MSCf6Z7N1Yut"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}