{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drive & Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/edoardorossi/Documents/Universita/Tesi/Tesi_GDrive\n",
      "Libraries imported\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = False\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  pass\n",
    "\n",
    "if IN_COLAB == True:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  %cd /content/gdrive/MyDrive/Tesi\n",
    "  PROJECT_PATH = '/content/gdrive/MyDrive/Tesi'\n",
    "  #!ls\n",
    "else:\n",
    "  %cd /Users/edoardorossi/Documents/Universita/Tesi/Tesi_GDrive\n",
    "  PROJECT_PATH = '/Users/edoardorossi/Documents/Universita/Tesi/Tesi_GDrive'\n",
    "\n",
    "import warnings\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if IN_COLAB == True:\n",
    "  sys.path.insert(0, os.path.abspath('functions'))\n",
    "  sys.path.insert(0, os.path.abspath(''))\n",
    "else:\n",
    "  sys.path.insert(0, os.path.abspath('functions'))\n",
    "  sys.path.insert(0, os.path.abspath(''))\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Lambda\n",
    "from keras.layers import Activation\n",
    "from keras.activations import exponential, relu\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Layer, InputSpec, Reshape\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "\n",
    "from pkl import store_data, load_data\n",
    "from functions.compressor import compress\n",
    "from functions.compute_target import compute_target\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "print(\"Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Anagrafica e CTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cta30_def_path = os.path.join(PROJECT_PATH, 'CTA30/DF_clean/clean_CTA_30_def.csv')\n",
    "CTA30_def = [cta30_def_path]\n",
    "  \n",
    "df_def = pd.read_csv(CTA30_def[0])\n",
    "\n",
    "cta30_18_path = os.path.join(PROJECT_PATH, 'CTA30/DF_clean/clean_CTA_30_2018.csv')\n",
    "CTA30_18 = [cta30_18_path]\n",
    "\n",
    "df = pd.read_csv(CTA30_18[0])\n",
    "df['VLV_RAF_FDBK_00'] = df['VLV_RAF_FDBK_00'] / 100\n",
    "df['VLV_SUR_FDBK_00'] = df['VLV_SUR_FDBK_00'] / 100\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "act_f_m = df.loc[:,'F_M_FDBK_00']\n",
    "a_f_m_reshaped = np.array(act_f_m).reshape(-1, 1)\n",
    "a_f_m_scaled = scaler.fit_transform(a_f_m_reshaped)\n",
    "\n",
    "min_f = np.min(a_f_m_scaled)\n",
    "max_f = np.max(a_f_m_scaled)\n",
    "\n",
    "a_raf_df = df['VLV_RAF_FDBK_00'] * 0.5\n",
    "a_sur_df = df['VLV_SUR_FDBK_00'] * 0.5 + 0.5000000001\n",
    "\n",
    "pca_df = compress(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim:  9\n",
      "inner layer1 dim:  32\n",
      "inner layer2 dim:  32\n",
      "output dim:  1\n"
     ]
    }
   ],
   "source": [
    "n = load_data('_.pkl')\n",
    "if IN_COLAB == True:\n",
    "    n = load_data('*.pkl')\n",
    "\n",
    "action_vector_dimension = 2\n",
    "\n",
    "# Architettura rete neurale\n",
    "input_dim = n['n_components'] + action_vector_dimension\n",
    "inner_dim_1 = 32\n",
    "inner_dim_2 = 32\n",
    "output_dim = 1\n",
    "\n",
    "print(\"input dim: \", input_dim)\n",
    "print(\"inner layer1 dim: \", inner_dim_1)\n",
    "print(\"inner layer2 dim: \", inner_dim_2)\n",
    "print(\"output dim: \", output_dim)\n",
    "\n",
    "# Definizione rete neurale\n",
    "rete_neurale = Sequential()\n",
    "rete_neurale.add(Dense(inner_dim_1, input_dim=input_dim, activation='relu'))\n",
    "rete_neurale.add(Dense(inner_dim_2, input_dim=inner_dim_1, activation='relu'))\n",
    "rete_neurale.add(Dense(output_dim, input_dim=inner_dim_2, activation='relu'))\n",
    "\n",
    "adam = Adam(learning_rate=0.001)\n",
    "rete_neurale.compile(loss='mse', optimizer=adam, metrics=['mae'])\n",
    "\n",
    "rete_neurale.load_weights('rete_neurale_DQN_1.h5')\n",
    "\n",
    "# Definisco funzione obiettivo per la massimizzazione della predizione \n",
    "def objective(x):\n",
    "    pca_s_prime = pca_df.loc[s_prime,:]\n",
    "    nn_input_prime = np.concatenate((pca_s_prime.values.reshape(7,1), x[0].reshape(1,1), x[1].reshape(1,1)), axis=0)\n",
    "    nn_input_prime = np.reshape(nn_input_prime, (1,input_dim))\n",
    "    funct = rete_neurale.predict(nn_input_prime, verbose=0)[0][0]\n",
    "    return -funct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimizing...\n",
      "time elapsed:  54.28936719894409 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.5355783]\n",
      "q predicted: [12.217145]\n",
      "q:  11.048988300561906\n",
      "current_episode =  0\n",
      "Episodio  0 / 10000\n",
      "\n",
      "\n",
      "minimizing...\n",
      "time elapsed:  58.04374694824219 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.5334561]\n",
      "q predicted: [10.777891]\n",
      "q:  9.753447651863098\n",
      "minimizing...\n",
      "time elapsed:  45.2493040561676 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.53030604]\n",
      "q predicted: [9.365186]\n",
      "q:  8.481697767972946\n",
      "minimizing...\n",
      "time elapsed:  47.72534799575806 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.5273432]\n",
      "q predicted: [7.9932656]\n",
      "q:  7.246673387289047\n",
      "minimizing...\n",
      "time elapsed:  65.14515423774719 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.523759]\n",
      "q predicted: [6.6684847]\n",
      "q:  6.05401211977005\n",
      "minimizing...\n",
      "time elapsed:  45.07673192024231 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.5210131]\n",
      "q predicted: [5.3978953]\n",
      "q:  4.910207110643387\n",
      "minimizing...\n",
      "time elapsed:  50.66403818130493 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.51909214]\n",
      "q predicted: [4.173895]\n",
      "q:  3.8084146082401276\n",
      "minimizing...\n",
      "time elapsed:  42.30661606788635 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.5155803]\n",
      "q predicted: [3.012346]\n",
      "q:  2.7626694560050966\n",
      "minimizing...\n",
      "time elapsed:  63.009403705596924 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.513384]\n",
      "q predicted: [1.9215775]\n",
      "q:  1.7807581067085265\n",
      "minimizing...\n",
      "time elapsed:  60.44948625564575 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.50969386]\n",
      "q predicted: [0.9155741]\n",
      "q:  0.8749860525131226\n",
      "minimizing...\n",
      "time elapsed:  59.15348196029663 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.5071335]\n",
      "q predicted: [0.00576465]\n",
      "q:  0.055901532713323834\n",
      "minimizing...\n",
      "time elapsed:  65.82375979423523 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.5047515]\n",
      "q predicted: [0.]\n",
      "q:  0.05047515034675598\n",
      "minimizing...\n",
      "time elapsed:  53.49286699295044 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.50339717]\n",
      "q predicted: [0.]\n",
      "q:  0.05033971667289734\n",
      "minimizing...\n",
      "time elapsed:  81.80374503135681 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.5020429]\n",
      "q predicted: [0.]\n",
      "q:  0.05020428895950318\n",
      "minimizing...\n",
      "time elapsed:  92.18011403083801 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4999468]\n",
      "q predicted: [0.]\n",
      "q:  0.0499946802854538\n",
      "minimizing...\n",
      "time elapsed:  64.10596895217896 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.49875572]\n",
      "q predicted: [0.]\n",
      "q:  0.04987557232379913\n",
      "minimizing...\n",
      "time elapsed:  35.18891429901123 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.49554226]\n",
      "q predicted: [0.]\n",
      "q:  0.049554225802421574\n",
      "minimizing...\n",
      "time elapsed:  29.04322600364685 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.49214214]\n",
      "q predicted: [0.]\n",
      "q:  0.04921421408653259\n",
      "minimizing...\n",
      "time elapsed:  36.92700505256653 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4945669]\n",
      "q predicted: [0.]\n",
      "q:  0.04945668876171112\n",
      "minimizing...\n",
      "time elapsed:  36.158223152160645 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.49339476]\n",
      "q predicted: [0.]\n",
      "q:  0.04933947622776032\n",
      "minimizing...\n",
      "time elapsed:  43.32319211959839 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.49218884]\n",
      "q predicted: [0.]\n",
      "q:  0.04921888411045075\n",
      "current_episode =  20\n",
      "Episodio  20 / 10000\n",
      "\n",
      "\n",
      "minimizing...\n",
      "time elapsed:  36.07482290267944 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4908713]\n",
      "q predicted: [0.]\n",
      "q:  0.049087131023406984\n",
      "minimizing...\n",
      "time elapsed:  38.017014026641846 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.49064377]\n",
      "q predicted: [0.]\n",
      "q:  0.04906437695026398\n",
      "minimizing...\n",
      "time elapsed:  41.48031687736511 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.49031878]\n",
      "q predicted: [0.]\n",
      "q:  0.0490318775177002\n",
      "minimizing...\n",
      "time elapsed:  43.64276194572449 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4900727]\n",
      "q predicted: [0.]\n",
      "q:  0.04900726974010468\n",
      "minimizing...\n",
      "time elapsed:  41.09351396560669 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4893624]\n",
      "q predicted: [0.]\n",
      "q:  0.04893623888492585\n",
      "minimizing...\n",
      "time elapsed:  33.919312953948975 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.48872355]\n",
      "q predicted: [0.]\n",
      "q:  0.04887235462665558\n",
      "minimizing...\n",
      "time elapsed:  43.66051506996155 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4888929]\n",
      "q predicted: [0.]\n",
      "q:  0.04888929128646851\n",
      "minimizing...\n",
      "time elapsed:  34.00584697723389 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4883172]\n",
      "q predicted: [0.]\n",
      "q:  0.04883171916007996\n",
      "minimizing...\n",
      "time elapsed:  29.76253390312195 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4869744]\n",
      "q predicted: [0.]\n",
      "q:  0.04869743883609772\n",
      "minimizing...\n",
      "time elapsed:  43.67894506454468 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.487459]\n",
      "q predicted: [0.]\n",
      "q:  0.04874590039253235\n",
      "minimizing...\n",
      "time elapsed:  38.49938201904297 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.48751083]\n",
      "q predicted: [0.]\n",
      "q:  0.04875108301639557\n",
      "minimizing...\n",
      "time elapsed:  44.03948187828064 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.48739973]\n",
      "q predicted: [0.]\n",
      "q:  0.04873997271060944\n",
      "minimizing...\n",
      "time elapsed:  40.28954601287842 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.487211]\n",
      "q predicted: [0.]\n",
      "q:  0.04872109889984131\n",
      "minimizing...\n",
      "time elapsed:  41.20395302772522 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.48689964]\n",
      "q predicted: [0.]\n",
      "q:  0.048689964413642886\n",
      "minimizing...\n",
      "time elapsed:  34.24063992500305 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4866728]\n",
      "q predicted: [0.]\n",
      "q:  0.048667278885841374\n",
      "minimizing...\n",
      "time elapsed:  38.54117298126221 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.48553067]\n",
      "q predicted: [0.]\n",
      "q:  0.04855306744575501\n",
      "minimizing...\n",
      "time elapsed:  37.838797092437744 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4863069]\n",
      "q predicted: [0.]\n",
      "q:  0.048630690574646\n",
      "minimizing...\n",
      "time elapsed:  40.794986963272095 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4868476]\n",
      "q predicted: [0.]\n",
      "q:  0.04868476092815399\n",
      "minimizing...\n",
      "time elapsed:  54.66234803199768 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.48676902]\n",
      "q predicted: [0.]\n",
      "q:  0.04867690205574036\n",
      "minimizing...\n",
      "time elapsed:  35.074957847595215 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.48611662]\n",
      "q predicted: [0.]\n",
      "q:  0.04861166179180146\n",
      "current_episode =  40\n",
      "Episodio  40 / 10000\n",
      "\n",
      "\n",
      "minimizing...\n",
      "time elapsed:  35.69217586517334 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.48575947]\n",
      "q predicted: [0.]\n",
      "q:  0.04857594668865204\n",
      "minimizing...\n",
      "time elapsed:  41.26029586791992 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4864209]\n",
      "q predicted: [0.]\n",
      "q:  0.048642089962959295\n",
      "minimizing...\n",
      "time elapsed:  39.16749382019043 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.48629254]\n",
      "q predicted: [0.]\n",
      "q:  0.04862925410270691\n",
      "minimizing...\n",
      "time elapsed:  40.779829025268555 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4856774]\n",
      "q predicted: [0.]\n",
      "q:  0.04856773912906647\n",
      "minimizing...\n",
      "time elapsed:  44.399388790130615 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4862355]\n",
      "q predicted: [0.]\n",
      "q:  0.04862354993820191\n",
      "minimizing...\n",
      "time elapsed:  38.32154703140259 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.48590758]\n",
      "q predicted: [0.]\n",
      "q:  0.048590758442878725\n",
      "minimizing...\n",
      "time elapsed:  53.11772012710571 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.48570722]\n",
      "q predicted: [0.]\n",
      "q:  0.048570722341537476\n",
      "minimizing...\n",
      "time elapsed:  42.3626070022583 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.48585612]\n",
      "q predicted: [0.]\n",
      "q:  0.04858561158180237\n",
      "minimizing...\n",
      "time elapsed:  42.702017068862915 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.4854981]\n",
      "q predicted: [0.]\n",
      "q:  0.04854981005191803\n",
      "minimizing...\n",
      "time elapsed:  54.321425914764404 seconds\n",
      "minimized\n",
      "predicting...\n",
      "q' predicted: [0.48564616]\n",
      "q predicted: [0.]\n",
      "q:  0.04856461584568024\n",
      "minimizing...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     45\u001b[0m \u001b[39m# Risultato della minimizzazione\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m objective_minimized \u001b[39m=\u001b[39m differential_evolution(objective, bounds\u001b[39m=\u001b[39;49mbounds)\n\u001b[1;32m     47\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     48\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtime elapsed: \u001b[39m\u001b[39m\"\u001b[39m, end_time \u001b[39m-\u001b[39m start_time, \u001b[39m\"\u001b[39m\u001b[39mseconds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:397\u001b[0m, in \u001b[0;36mdifferential_evolution\u001b[0;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol, updating, workers, constraints, x0, integrality, vectorized)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39m# using a context manager means that any created Pool objects are\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# cleared up.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39mwith\u001b[39;00m DifferentialEvolutionSolver(func, bounds, args\u001b[39m=\u001b[39margs,\n\u001b[1;32m    383\u001b[0m                                  strategy\u001b[39m=\u001b[39mstrategy,\n\u001b[1;32m    384\u001b[0m                                  maxiter\u001b[39m=\u001b[39mmaxiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m                                  integrality\u001b[39m=\u001b[39mintegrality,\n\u001b[1;32m    396\u001b[0m                                  vectorized\u001b[39m=\u001b[39mvectorized) \u001b[39mas\u001b[39;00m solver:\n\u001b[0;32m--> 397\u001b[0m     ret \u001b[39m=\u001b[39m solver\u001b[39m.\u001b[39;49msolve()\n\u001b[1;32m    399\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:998\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[39mfor\u001b[39;00m nit \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxiter \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    996\u001b[0m     \u001b[39m# evolve the population by a generation\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 998\u001b[0m         \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    999\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m   1000\u001b[0m         warning_flag \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/scipy/optimize/_differentialevolution.py:1385\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1383\u001b[0m     feasible \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1384\u001b[0m     cv \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39matleast_2d([\u001b[39m0.\u001b[39m])\n\u001b[0;32m-> 1385\u001b[0m     energy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(parameters)\n\u001b[1;32m   1386\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1388\u001b[0m \u001b[39m# compare trial and population member\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/scipy/_lib/_util.py:372\u001b[0m, in \u001b[0;36m_FunctionWrapper.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 372\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(x, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs)\n",
      "Cell \u001b[0;32mIn[14], line 33\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     31\u001b[0m nn_input_prime \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((pca_s_prime\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m7\u001b[39m,\u001b[39m1\u001b[39m), x[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m), x[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     32\u001b[0m nn_input_prime \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(nn_input_prime, (\u001b[39m1\u001b[39m,input_dim))\n\u001b[0;32m---> 33\u001b[0m funct \u001b[39m=\u001b[39m rete_neurale\u001b[39m.\u001b[39;49mpredict(nn_input_prime, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m     34\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mfunct\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/keras/engine/training.py:2220\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2211\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m   2212\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2213\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2214\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2217\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2218\u001b[0m         )\n\u001b[0;32m-> 2220\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   2221\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   2222\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2223\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m   2224\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2225\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2226\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2227\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2228\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2229\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2230\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[1;32m   2231\u001b[0m )\n\u001b[1;32m   2233\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/keras/engine/data_adapter.py:1582\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1581\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1582\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/keras/engine/data_adapter.py:1262\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   1261\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1262\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1263\u001b[0m     x,\n\u001b[1;32m   1264\u001b[0m     y,\n\u001b[1;32m   1265\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1266\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1267\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[1;32m   1268\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1269\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1270\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1271\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1272\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1273\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[1;32m   1274\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1275\u001b[0m )\n\u001b[1;32m   1277\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/keras/engine/data_adapter.py:308\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m indices\n\u001b[1;32m    303\u001b[0m \u001b[39m# We prefetch a single element. Computing large permutations can take\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39m# quite a while so we don't want to wait for prefetching over an epoch\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m# boundary to trigger the next permutation. On the other hand, too many\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[39m# simultaneous shuffles can contend on a hardware level and degrade all\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# performance.\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mmap(permutation)\u001b[39m.\u001b[39mprefetch(\u001b[39m1\u001b[39m)\n\u001b[1;32m    310\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mslice_batch_indices\u001b[39m(indices):\n\u001b[1;32m    311\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \n\u001b[1;32m    313\u001b[0m \u001b[39m    This step can be accomplished in several ways. The most natural is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39m      A Dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2202\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2199\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2200\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2201\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2202\u001b[0m   \u001b[39mreturn\u001b[39;00m MapDataset(\u001b[39mself\u001b[39;49m, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   2203\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2204\u001b[0m   \u001b[39mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2205\u001b[0m       \u001b[39mself\u001b[39m,\n\u001b[1;32m   2206\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2209\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   2210\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:5400\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5398\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5399\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[1;32m   5401\u001b[0m     map_func,\n\u001b[1;32m   5402\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[1;32m   5403\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[1;32m   5404\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[1;32m   5405\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[1;32m   5406\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[1;32m   5407\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   5408\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5411\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m   5412\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m    272\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2610\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2601\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   2602\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   2603\u001b[0m \n\u001b[1;32m   2604\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2608\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   2609\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2610\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[1;32m   2611\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2612\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2613\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2576\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2574\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2575\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2576\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2577\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m   2578\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   2579\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   2667\u001b[0m ]\n\u001b[1;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   2673\u001b[0m         args,\n\u001b[1;32m   2674\u001b[0m         kwargs,\n\u001b[1;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1153\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1151\u001b[0m   deps_control_manager \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mNullContextmanager()\n\u001b[0;32m-> 1153\u001b[0m \u001b[39mwith\u001b[39;00m func_graph\u001b[39m.\u001b[39mas_default(), deps_control_manager \u001b[39mas\u001b[39;00m deps_ctx:\n\u001b[1;32m   1154\u001b[0m   current_scope \u001b[39m=\u001b[39m variable_scope\u001b[39m.\u001b[39mget_variable_scope()\n\u001b[1;32m   1155\u001b[0m   default_use_resource \u001b[39m=\u001b[39m current_scope\u001b[39m.\u001b[39muse_resource\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/tensorflow/python/framework/auto_control_deps.py:464\u001b[0m, in \u001b[0;36mAutomaticControlDependencies.__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    461\u001b[0m resource_inputs \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    462\u001b[0m \u001b[39m# Check for any resource inputs. If we find any, we update control_inputs\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[39m# and last_write_to_resource.\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m \u001b[39mfor\u001b[39;00m inp, resource_type \u001b[39min\u001b[39;00m _get_resource_inputs(op):\n\u001b[1;32m    465\u001b[0m   is_read \u001b[39m=\u001b[39m resource_type \u001b[39m==\u001b[39m ResourceType\u001b[39m.\u001b[39mREAD_ONLY\n\u001b[1;32m    466\u001b[0m   input_id \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mtensor_id(inp)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/tensorflow/python/framework/auto_control_deps.py:671\u001b[0m, in \u001b[0;36m_get_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    665\u001b[0m saturated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m _acd_resource_resolvers_registry\u001b[39m.\u001b[39mlist():\n\u001b[1;32m    667\u001b[0m   \u001b[39m# Resolvers should return true if they are updating the list of\u001b[39;00m\n\u001b[1;32m    668\u001b[0m   \u001b[39m# resource_inputs.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m   \u001b[39m# TODO(srbs): An alternate would be to just compare the old and new set\u001b[39;00m\n\u001b[1;32m    670\u001b[0m   \u001b[39m# but that may not be as fast.\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m   updated \u001b[39m=\u001b[39m _acd_resource_resolvers_registry\u001b[39m.\u001b[39;49mlookup(key)(op, reads, writes)\n\u001b[1;32m    672\u001b[0m   \u001b[39mif\u001b[39;00m updated:\n\u001b[1;32m    673\u001b[0m     \u001b[39m# Conservatively remove any resources from `reads` that are also writes.\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     reads \u001b[39m=\u001b[39m reads\u001b[39m.\u001b[39mdifference(writes)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tesi_env/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:6483\u001b[0m, in \u001b[0;36m_resource_resolver\u001b[0;34m(op, resource_reads, resource_writes)\u001b[0m\n\u001b[1;32m   6480\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Updates resource inputs for tf.data ops with indirect dependencies.\"\"\"\u001b[39;00m\n\u001b[1;32m   6482\u001b[0m updated \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 6483\u001b[0m \u001b[39mif\u001b[39;00m op\u001b[39m.\u001b[39mtype \u001b[39min\u001b[39;00m [\n\u001b[1;32m   6484\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mDatasetToSingleElement\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetToTFRecord\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mReduceDataset\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   6485\u001b[0m ]:\n\u001b[1;32m   6486\u001b[0m   reads, writes \u001b[39m=\u001b[39m _collect_resource_inputs(op)\n\u001b[1;32m   6487\u001b[0m   \u001b[39mfor\u001b[39;00m inp \u001b[39min\u001b[39;00m reads:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "[S, feat] = df.shape\n",
    "current_state = 0\n",
    "s = current_state\n",
    "current_episode = 0\n",
    "total_episodes = 10000\n",
    "\n",
    "alpha = 0.1\n",
    "gamma = 1\n",
    "\n",
    "for current_episode in range(total_episodes):\n",
    "\n",
    "    s_prime = s+1\n",
    "    if s_prime > S-1:\n",
    "      print(\"s =\", s)\n",
    "      break\n",
    "    # a1 = frequenza sul motore di mandata\n",
    "    a1 = df.loc[s,'F_M_FDBK_00']\n",
    "\n",
    "    # a2 = percentuale di apertura delle valvole caldo/freddo (esclusive)\n",
    "    a_raf = df.loc[s,'VLV_RAF_FDBK_00']\n",
    "    a_sur = df.loc[s,'VLV_SUR_FDBK_00']\n",
    "    if a_raf == 0:\n",
    "      if a_sur == 0:\n",
    "        a2 = 0\n",
    "      else:\n",
    "        a2 = a_sur_df[s]\n",
    "    else:\n",
    "      a2 = a_raf_df[s]\n",
    "       \n",
    "    a = (a1,a2)\n",
    "\n",
    "    # r = reward \n",
    "    r = -df.loc[s,'PW_ATT_M_00']\n",
    "\n",
    "    # Condizioni iniziali random per la minimizzazione\n",
    "    data_f = a_f_m_scaled\n",
    "    a0_f = data_f[np.random.randint(len(data_f))]\n",
    "    a0_v = np.random.rand()\n",
    "    x0 = [a0_f, a0_v]\n",
    "  \n",
    "    # Dominio della minimizzazione \n",
    "    bounds = [(min_f, max_f), (0,1)]\n",
    "    print(\"minimizing...\")\n",
    "    start_time = time.time()\n",
    "    # Risultato della minimizzazione\n",
    "    objective_minimized = differential_evolution(objective, bounds=bounds)\n",
    "    end_time = time.time()\n",
    "    print(\"time elapsed: \", end_time - start_time, \"seconds\")\n",
    "    print(\"minimized\")\n",
    "\n",
    "    print(\"predicting...\")\n",
    "    # Compongo input della predizione di q'\n",
    "    a1_prime_input = np.array([objective_minimized.x[0]]).reshape(1,1)\n",
    "    a2_prime_input = objective_minimized.x[1].reshape(1,1)\n",
    "    s_prime_input = pca_df.loc[s_prime,:].values.reshape(7,1)\n",
    "    conc1 = np.concatenate((s_prime_input, a1_prime_input), axis=0)\n",
    "    a2_prime_input = np.expand_dims(a2_prime_input, axis=1).reshape(1,1)\n",
    "    conc2 = np.concatenate((conc1, a2_prime_input), axis=0)\n",
    "    nn_input_prime = np.reshape(conc2, (1,input_dim))\n",
    "    # Compongo input della predizione di q\n",
    "    a1_input = np.array([a1]).reshape(1,1)\n",
    "    a2_input = np.array([a2]).reshape(1,1)\n",
    "    s_input = pca_df.loc[s,:].values.reshape(7,1)\n",
    "    conc1 = np.concatenate((s_input, a1_input), axis=0)\n",
    "    a2_input = np.expand_dims(a2_input, axis=1).reshape(1,1)\n",
    "    conc2 = np.concatenate((conc1, a2_input), axis=0)\n",
    "    nn_input = np.reshape(conc2, (1,input_dim))\n",
    "\n",
    "    # Predizione di q'\n",
    "    q_prime = rete_neurale.predict(nn_input_prime, verbose = 0)[0]\n",
    "    print(\"q' predicted:\", q_prime)\n",
    "    q_prime = q_prime[0]\n",
    "\n",
    "    # Predizione di q\n",
    "    q_ = rete_neurale.predict(nn_input, verbose = 0)[0] \n",
    "    print(\"q predicted:\", q_)\n",
    "    q_ = q_[0]\n",
    "\n",
    "    # q = avr + gamma*max(q')\n",
    "    q = q_ + alpha*(r + gamma*q_prime - q_)\n",
    "\n",
    "    print(\"q: \", q)\n",
    "    # Calcola il valore target per il training della rete neurale\n",
    "    target = q\n",
    "    target = np.array([target])\n",
    "\n",
    "    # Aggiornamento della rete neurale\n",
    "    rete_neurale.fit(nn_input, target, epochs=1, verbose=0)\n",
    "\n",
    "    # Aggiornamento  dello stato corrente\n",
    "    s = s_prime\n",
    "\n",
    "    # Plot statistiche ogni n episodi    \n",
    "    n_print = 20\n",
    "    if current_episode%n_print == 0:\n",
    "      print(\"current_episode = \", current_episode)\n",
    "      print(\"Episodio \",current_episode,\"/\",total_episodes)\n",
    "      print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 36\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m# r = reward \u001b[39;00m\n\u001b[1;32m     33\u001b[0m r \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mdf\u001b[39m.\u001b[39mloc[s,\u001b[39m'\u001b[39m\u001b[39mPW_ATT_M_00\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     35\u001b[0m target \u001b[39m=\u001b[39m compute_target(min_f, max_f, objective, s_prime, \n\u001b[0;32m---> 36\u001b[0m                         a[\u001b[39m1\u001b[39m], a[\u001b[39m2\u001b[39;49m], s, r, alpha, gamma, \n\u001b[1;32m     37\u001b[0m                         rete_neurale, pca_df, input_dim)\n\u001b[1;32m     39\u001b[0m \u001b[39m# Aggiornamento della rete neurale\u001b[39;00m\n\u001b[1;32m     40\u001b[0m rete_neurale\u001b[39m.\u001b[39mfit(nn_input, target, epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "[S, feat] = df.shape\n",
    "current_state = 0\n",
    "s = current_state\n",
    "current_episode = 0\n",
    "total_episodes = 10000\n",
    "\n",
    "alpha = 0.1\n",
    "gamma = 1\n",
    "\n",
    "for current_episode in range(total_episodes):\n",
    "\n",
    "    s_prime = s+1\n",
    "    if s_prime > S-1:\n",
    "      print(\"s =\", s)\n",
    "      break\n",
    "    # a1 = frequenza sul motore di mandata\n",
    "    a1 = df.loc[s,'F_M_FDBK_00']\n",
    "\n",
    "    # a2 = percentuale di apertura delle valvole caldo/freddo (esclusive)\n",
    "    a_raf = df.loc[s,'VLV_RAF_FDBK_00']\n",
    "    a_sur = df.loc[s,'VLV_SUR_FDBK_00']\n",
    "    if a_raf == 0:\n",
    "      if a_sur == 0:\n",
    "        a2 = 0\n",
    "      else:\n",
    "        a2 = a_sur_df[s]\n",
    "    else:\n",
    "      a2 = a_raf_df[s]\n",
    "       \n",
    "    a = (a1,a2)\n",
    "\n",
    "    # r = reward \n",
    "    r = -df.loc[s,'PW_ATT_M_00']\n",
    "\n",
    "    target = compute_target(min_f, max_f, objective, s_prime, \n",
    "                            a[1], a[2], s, r, alpha, gamma, \n",
    "                            rete_neurale, pca_df, input_dim)\n",
    "\n",
    "    # Aggiornamento della rete neurale\n",
    "    rete_neurale.fit(nn_input, target, epochs=1, verbose=0)\n",
    "\n",
    "    # Aggiornamento  dello stato corrente\n",
    "    s = s_prime\n",
    "\n",
    "    # Plot statistiche ogni n episodi    \n",
    "    n_print = 20\n",
    "    if current_episode%n_print == 0:\n",
    "      print(\"current_episode = \", current_episode)\n",
    "      print(\"Episodio \",current_episode,\"/\",total_episodes)\n",
    "      print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.99308544e-01, -2.53150821e-01,  1.90691739e-01,\n",
       "          6.80205226e-03, -9.76977870e-02,  2.69673318e-01,\n",
       "          5.76299429e-02,  3.51702601e-01,  3.56871307e-01,\n",
       "         -3.44222598e-02, -7.47099593e-02,  1.70016527e-01,\n",
       "          3.25891733e-01,  4.90468740e-03, -9.05256867e-02,\n",
       "         -3.32993805e-01, -2.96946734e-01,  1.44851893e-01,\n",
       "          1.63999468e-01, -1.43457100e-01,  4.06609476e-02,\n",
       "         -3.81809652e-01,  1.01603389e-01,  1.64344400e-01,\n",
       "          1.16929471e-01, -8.14542472e-02,  3.19382668e-01,\n",
       "         -2.25958675e-02,  3.34421217e-01,  1.83908571e-03,\n",
       "          3.52562755e-01, -1.33883685e-01],\n",
       "        [-3.07298005e-02, -1.21894583e-01,  2.64793247e-01,\n",
       "         -2.45333239e-01,  1.97341945e-02, -1.76741064e-01,\n",
       "          1.43447369e-01, -3.18900168e-01,  2.89489180e-01,\n",
       "         -2.77845860e-01, -1.67392612e-01,  3.19974840e-01,\n",
       "          3.23116094e-01, -2.75554359e-01,  2.05121905e-01,\n",
       "         -3.72754693e-01, -1.18248723e-01,  5.20452484e-02,\n",
       "         -4.75865006e-02, -3.16990912e-01,  6.47600591e-02,\n",
       "         -1.69144068e-02,  2.50715643e-01, -3.07857573e-01,\n",
       "         -5.74151278e-02, -2.58806735e-01, -3.53510141e-01,\n",
       "         -1.14708260e-01,  3.44819218e-01,  2.32992083e-01,\n",
       "          8.22796524e-02,  1.54633135e-01],\n",
       "        [ 1.62533432e-01, -2.07631931e-01, -1.39170587e-02,\n",
       "         -1.41680896e-01,  2.36437500e-01,  3.34902972e-01,\n",
       "         -1.94965497e-01,  2.78860837e-01,  9.68963206e-02,\n",
       "          2.79796183e-01,  1.42631546e-01, -1.93518009e-02,\n",
       "          2.92439580e-01,  2.45084494e-01, -1.94413975e-01,\n",
       "         -3.28598291e-01,  4.85788360e-02,  3.75062376e-02,\n",
       "          1.08823448e-01,  1.36436179e-01, -1.11120671e-01,\n",
       "         -1.32139981e-01,  2.98291892e-01,  2.53468156e-02,\n",
       "         -3.48389536e-01, -1.09416246e-02,  2.26640388e-01,\n",
       "         -1.62483722e-01, -2.68234134e-01, -2.41596982e-01,\n",
       "          2.87175328e-01, -2.78444052e-01],\n",
       "        [-3.69740337e-01,  1.66503266e-01, -1.90749496e-01,\n",
       "          3.42594594e-01,  1.01744458e-01, -1.16227180e-01,\n",
       "         -8.01422298e-02,  8.47613811e-02, -2.78652042e-01,\n",
       "         -1.03138268e-01,  2.38854121e-02, -2.96371996e-01,\n",
       "         -1.10312462e-01,  2.17008024e-01,  1.85942382e-01,\n",
       "         -3.41589421e-01,  1.29176438e-01,  2.35729799e-01,\n",
       "          3.37883264e-01, -3.21819901e-01,  2.57554680e-01,\n",
       "          1.05839111e-01,  4.63470221e-02,  2.92852610e-01,\n",
       "          6.48835599e-02, -3.40678245e-01, -1.91607296e-01,\n",
       "          3.18554431e-01, -3.53682451e-02, -2.76985049e-01,\n",
       "         -6.37396574e-02, -3.47106904e-01],\n",
       "        [-3.29867303e-01, -2.01592483e-02,  3.05168539e-01,\n",
       "          2.76540518e-02, -1.07085653e-01, -1.02080584e-01,\n",
       "         -2.85280138e-01, -2.29845896e-01, -2.83994675e-02,\n",
       "          3.07282001e-01, -3.76771539e-01,  1.61806121e-01,\n",
       "          1.47643030e-01,  4.24939394e-03,  3.82742584e-02,\n",
       "         -1.40073434e-01,  1.03226259e-01, -1.10246807e-01,\n",
       "          3.40902418e-01,  2.94910848e-01, -2.27033556e-01,\n",
       "         -1.07224561e-01,  1.29763752e-01,  3.17020386e-01,\n",
       "          2.21185356e-01, -5.99661469e-03, -3.13694358e-01,\n",
       "          8.84874463e-02,  1.67895928e-01,  2.87936360e-01,\n",
       "         -2.80846357e-02, -2.54766315e-01],\n",
       "        [-3.19929063e-01,  1.04618393e-01, -3.57464850e-02,\n",
       "         -2.45421708e-01,  3.03382784e-01, -2.11505175e-01,\n",
       "         -1.07888401e-01, -3.45156789e-02, -1.62833825e-01,\n",
       "          2.58841664e-01,  1.85406491e-01,  3.65437955e-01,\n",
       "         -3.68500859e-01, -6.64639771e-02,  2.95201808e-01,\n",
       "          2.62003958e-01, -3.17127526e-01,  3.63486335e-02,\n",
       "         -3.46797824e-01,  2.07305208e-01, -2.40171701e-01,\n",
       "          3.53774905e-01, -4.21641171e-02, -1.66092843e-01,\n",
       "         -2.90861934e-01, -1.82312027e-01, -2.53440648e-01,\n",
       "         -3.74345958e-01,  3.34809542e-01,  3.70556623e-01,\n",
       "          3.46881896e-01, -2.42753282e-01],\n",
       "        [-7.22326636e-02, -2.10338369e-01, -3.60726893e-01,\n",
       "         -3.72326583e-01, -1.16218276e-01, -3.45946044e-01,\n",
       "         -3.04384351e-01, -3.19383740e-02, -2.22961575e-01,\n",
       "          1.64792478e-01,  3.47420961e-01, -1.82777405e-01,\n",
       "         -2.97098786e-01, -3.65880966e-01,  1.34291202e-01,\n",
       "          3.67255330e-01,  1.71651930e-01,  2.20222607e-01,\n",
       "         -1.58765718e-01, -1.07101046e-01, -2.29103386e-01,\n",
       "          6.23130724e-02,  2.02179462e-01,  8.67089927e-02,\n",
       "          1.45085365e-01, -2.97131538e-01, -8.18715841e-02,\n",
       "         -3.17394495e-01,  1.60147876e-01,  2.69035697e-01,\n",
       "         -2.47157350e-01, -1.75287142e-01],\n",
       "        [-1.08026266e-02,  4.07268070e-02,  1.52319670e-04,\n",
       "         -2.22210944e-01, -5.11922222e-03, -1.55569583e-01,\n",
       "         -3.03970098e-01, -3.46635818e-01,  6.48513958e-02,\n",
       "          1.40535250e-01,  2.26889610e-01,  3.54006112e-01,\n",
       "          2.06615165e-01, -1.21897846e-01, -3.69187623e-01,\n",
       "          2.44289145e-01,  1.24117501e-01,  2.67430186e-01,\n",
       "         -3.78762454e-01,  4.49083820e-02, -1.88444540e-01,\n",
       "          2.64995575e-01, -2.12455899e-01, -3.29107583e-01,\n",
       "         -1.70274734e-01, -3.36910993e-01,  1.67269796e-01,\n",
       "          3.47920991e-02,  3.52963924e-01,  1.47429794e-01,\n",
       "         -3.56238276e-01, -6.90454543e-02],\n",
       "        [-2.63214469e-01, -2.46447414e-01, -1.26252294e-01,\n",
       "          3.29971313e-04, -1.55684039e-01, -3.57406259e-01,\n",
       "         -3.73012632e-01,  3.50198358e-01, -2.78010458e-01,\n",
       "          3.10538024e-01, -2.54325420e-01, -2.15351149e-01,\n",
       "          3.79851907e-01, -2.90135860e-01,  2.18316704e-01,\n",
       "         -2.90850729e-01, -6.76761866e-02, -3.07512522e-01,\n",
       "          2.04058260e-01, -2.51932740e-01,  1.40905648e-01,\n",
       "         -1.97791427e-01, -3.16757739e-01,  3.35993618e-01,\n",
       "          2.16596454e-01,  3.33385259e-01, -3.82148743e-01,\n",
       "         -2.34885037e-01, -1.36123806e-01,  2.29876250e-01,\n",
       "         -3.68364304e-01,  1.29933745e-01]], dtype=float32),\n",
       " array([ 0.        ,  0.01617968,  0.        ,  0.        , -0.00837394,\n",
       "         0.        ,  0.        ,  0.        , -0.01543073, -0.01623544,\n",
       "        -0.01528495,  0.01595432, -0.0134987 ,  0.        ,  0.        ,\n",
       "         0.01648598, -0.01581765, -0.01567776,  0.        , -0.0157231 ,\n",
       "         0.        ,  0.01812367,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.01627827,  0.01288142, -0.01520254, -0.01568647,\n",
       "         0.        ,  0.        ], dtype=float32),\n",
       " array([[-0.05781361, -0.1035836 ,  0.1430744 , ..., -0.28909323,\n",
       "          0.29261383,  0.29492614],\n",
       "        [ 0.2042745 ,  0.0862157 , -0.25772464, ..., -0.18110195,\n",
       "         -0.27391353, -0.24855843],\n",
       "        [ 0.20363727, -0.20727575, -0.27970895, ...,  0.01476181,\n",
       "          0.05608702, -0.17627573],\n",
       "        ...,\n",
       "        [ 0.17035744, -0.01764283, -0.02240101, ..., -0.30779725,\n",
       "          0.2843749 ,  0.24104656],\n",
       "        [ 0.14699188,  0.18663245,  0.05771959, ...,  0.16071406,\n",
       "          0.22566298, -0.2155235 ],\n",
       "        [ 0.07779181,  0.21575424,  0.11222181, ...,  0.06136516,\n",
       "         -0.11540698, -0.21492386]], dtype=float32),\n",
       " array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.0162318 ,\n",
       "        -0.01606806, -0.01597375, -0.01535809,  0.        ,  0.        ,\n",
       "         0.01617408,  0.01616673,  0.01620042,  0.        ,  0.        ,\n",
       "         0.        , -0.01574525, -0.01605549,  0.01617051,  0.        ,\n",
       "        -0.01606751,  0.        , -0.01522532,  0.0165443 , -0.01284932,\n",
       "        -0.01604861,  0.        , -0.0160788 ,  0.        , -0.00511068,\n",
       "        -0.01608225, -0.01604995], dtype=float32),\n",
       " array([[ 0.2539572 ],\n",
       "        [ 0.30154878],\n",
       "        [ 0.16014624],\n",
       "        [-0.16879454],\n",
       "        [-0.16002285],\n",
       "        [ 0.2688827 ],\n",
       "        [ 0.09248953],\n",
       "        [ 0.00802553],\n",
       "        [-0.04548064],\n",
       "        [ 0.25732386],\n",
       "        [-0.3314509 ],\n",
       "        [-0.38529354],\n",
       "        [-0.22249909],\n",
       "        [-0.36040986],\n",
       "        [ 0.25955564],\n",
       "        [ 0.22747064],\n",
       "        [ 0.02902073],\n",
       "        [ 0.2151994 ],\n",
       "        [-0.35456252],\n",
       "        [-0.06307927],\n",
       "        [ 0.26652893],\n",
       "        [-0.421977  ],\n",
       "        [ 0.00608716],\n",
       "        [-0.05421164],\n",
       "        [ 0.11196165],\n",
       "        [ 0.19592212],\n",
       "        [ 0.42005438],\n",
       "        [ 0.3333227 ],\n",
       "        [ 0.3176813 ],\n",
       "        [ 0.38070485],\n",
       "        [ 0.36853087],\n",
       "        [ 0.20140575]], dtype=float32),\n",
       " array([-0.01612349], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rete_neurale.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = rete_neurale.predict(nn_input, verbose = 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00228734, 0.99852852])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_minimized.x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "current_state = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rete_neurale.save_weights('rete_neurale_DQN_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
