{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drive & Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/edoardorossi/Documents/Universita/Tesi/Tesi_GDrive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 14:43:06.876574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported\n"
     ]
    }
   ],
   "source": [
    "IN_COLAB = False\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  pass\n",
    "\n",
    "if IN_COLAB == True:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  %cd /content/gdrive/MyDrive/Tesi_GDrive\n",
    "  PROJECT_PATH = '/content/gdrive/MyDrive/Tesi_GDrive'\n",
    "  #!ls\n",
    "else:\n",
    "  %cd /Users/edoardorossi/Documents/Universita/Tesi/Tesi_GDrive\n",
    "  PROJECT_PATH = '/Users/edoardorossi/Documents/Universita/Tesi/Tesi_GDrive'\n",
    "\n",
    "import warnings\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if IN_COLAB == True:\n",
    "  sys.path.insert(0, os.path.abspath('functions'))\n",
    "  sys.path.insert(0, os.path.abspath(''))\n",
    "else:\n",
    "  sys.path.insert(0, os.path.abspath('functions'))\n",
    "  sys.path.insert(0, os.path.abspath(''))\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Lambda\n",
    "from keras.layers import Activation\n",
    "from keras.activations import exponential, relu\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras.layers import Input, Layer, InputSpec, Reshape\n",
    "#from tensorflow.keras import initializers\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "\n",
    "from pkl import store_data, load_data\n",
    "#from functions.compressor import compress\n",
    "from functions.compressor_param import compress_2\n",
    "from functions.mapping import ind2sub, sub2ind3d\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"Libraries imported\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 2176378 rows and 76 columns\n"
     ]
    }
   ],
   "source": [
    "cta30_def_path = os.path.join(PROJECT_PATH, 'CTA30/DF_clean/clean_CTA_30_def.csv')  \n",
    "df_def = pd.read_csv(cta30_def_path)\n",
    "\n",
    "\n",
    "cta30_18_path = os.path.join(PROJECT_PATH, 'CTA30/DF_clean/clean_CTA_30_2018.csv')\n",
    "cta30_19_path = os.path.join(PROJECT_PATH, 'CTA30/DF_clean/clean_CTA_30_2019.csv')\n",
    "cta30_20_path = os.path.join(PROJECT_PATH, 'CTA30/DF_clean/clean_CTA_30_2020.csv')\n",
    "cta30_21_path = os.path.join(PROJECT_PATH, 'CTA30/DF_clean/clean_CTA_30_2021.csv')\n",
    "cta30_22_path = os.path.join(PROJECT_PATH, 'CTA30/DF_clean/clean_CTA_30_2022.csv')\n",
    "\n",
    "df18= pd.read_csv(cta30_18_path)\n",
    "df19= pd.read_csv(cta30_19_path)\n",
    "df20= pd.read_csv(cta30_20_path)\n",
    "df21= pd.read_csv(cta30_21_path)\n",
    "df22= pd.read_csv(cta30_22_path)\n",
    "\n",
    "df = pd.concat([df18, df19, df20, df21, df22], ignore_index=True)\n",
    "\n",
    "[r,c] = df.shape\n",
    "print(\"The dataset has\", r, \"rows and\", c, \"columns\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scale_norm = MinMaxScaler()\n",
    "df_norm = pd.DataFrame(scale_norm.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANTIGELO_ALARM_00     0.000000\n",
       "AUTOMAN_M_CMD_00      0.599193\n",
       "AUTOMAN_M_ST_00       0.599193\n",
       "AUTOMAN_R_CMD_00      0.741034\n",
       "AUTOMAN_R_ST_00       0.741035\n",
       "                       ...    \n",
       "FILTER_ALRM_01        0.000000\n",
       "FILTER_ALRM_00        0.000000\n",
       "FILTER_ALRM_02        0.000000\n",
       "METER_M_DIAG_00      16.350054\n",
       "METER_R_DIAG_00      16.353089\n",
       "Length: 76, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_scale = StandardScaler()\n",
    "df_st = pd.DataFrame(st_scale.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
